---
title: "Head Motion Benchmark"
output: rmarkdown::html_vignette
date: "`r lubridate::today()`"
vignette: >
  %\VignetteIndexEntry{Head Motion Benchmark}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction

In this project, we used FiberFox to simulate entire dMRI series for ABCD, HCP, DSIQ5, and HASC55
data. Head motion was then introduced by applying rigid transforms to the streamline
data (translations and rotations). Then, QSIPrep used both SHORELine and Eddy to
estimate the introduced head motion — analysis of these results are evaluated in this notebook.

# Libraries & Setup

```{r setup, include=FALSE}
# TODO chunk names

knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
library(dplyr)
library(tidyr)
library(broom)
library(ggpattern)
library(emmeans)
library(tibble)
library(janitor)
library(gtsummary)
library(gt)
library(here)
library(stringr)
library(ggdist)
library(ggplot2); theme_set(theme_minimal())
library(viridis)

library(SHORELINEPaper) # for the data
```

The data are available on OSF at [this link](osf.io/7twne).
This package internally downloads and cleans them for
your convenience. They're available preprocessed within the package:

```{r}
# for viewing the preprocessed data
motion_df <- SHORELINEPaper::motion_df %>%
  as_tibble()
data("error_df_wsetting")
data("error_rmse_wsetting") # for analysis of estimated motion
```

# Sample

The table below shows the number of `b0`'s for each scheme:

```{r}
# QUESTION the Num b > 1 seem to be slightly higher and lower than table 1
motion_df %>%
  filter(
    iternum == 1 &
      method == "SHORELine" &
      denoising == "none" &
      bval > 100 &
      setting == "Affine") %>%
  group_by(percent_motion, scheme) %>%
  summarise(max_b = max(bval),
            num_b = n()) %>%
  ungroup() %>%
  distinct(scheme, max_b, num_b) %>%
  t() %>%
  row_to_names(1) %>%
  data.frame() %>%
  add_row(ABCD = "Shelled", HCP = "Shelled", DSIQ5 = "Cartesian", HASC55 = "Random", .before = 1) -> tab1

rownames(tab1) <- c("Type", "Max. b", "Num. b > 0")

gt(tab1, rownames_to_stub = TRUE) %>%
  tab_header("Scheme properties and processing pipeline runs") %>%
  opt_table_font("Times New Roman")

```

Below is a breakdown of how the runs were accumulated:

```{r}
motion_df %>%
  filter(volnum == 0) %>%
  select(Algorithm = method, Model = setting, Denoising = denoising, percent_motion, scheme) %>%
  group_by_all() %>%
  summarise(n = n()) %>%
  pivot_wider(names_from = scheme, values_from = n) %>%
  ungroup() %>%
  mutate(across(where(is.numeric), ~ ifelse(is.na(.), 0, .))) %>%
  mutate(Denoising = ifelse(Denoising == "none", "None", "MP-PCA")) %>%
  mutate(percent_motion = paste0(as.character(percent_motion), " %")) %>%
  # insert empty string for tidyness
  mutate(across(where(is.factor), as.character)) %>%
  group_by(Algorithm, Model, Denoising) %>%
  mutate_at(vars(Algorithm:Denoising), ~ replace(.x, duplicated(.x), "")) %>%
  ungroup() %>%
  select(-Algorithm) %>%
  gt() %>%
  tab_spanner("# Pipeline Runs", columns = ABCD:HASC55) %>%
  cols_align(align = "right", columns = percent_motion:HASC55) %>%
  tab_row_group(
    label = "Eddy",
    rows = 1:12
  ) %>%
  tab_row_group(
    label = "SHORELine",
    rows = 13:24
  ) %>%
  opt_table_font("Times New Roman")
  
```

And finally the total scans and volumes:

```{r}
motion_df %>%
  filter(volnum == 0) %>%
  select(Algorithm = method, Model = setting, Denoising = denoising, percent_motion, scheme) %>%
  group_by_all() %>%
  summarise(n = n()) %>%
  pivot_wider(names_from = scheme, values_from = n) %>%
  ungroup() %>%
  mutate(across(where(is.numeric), ~ ifelse(is.na(.), 0, .))) %>%
  mutate(Denoising = ifelse(Denoising == "none", "None", "MP-PCA")) %>%
  mutate(percent_motion = paste0(as.character(percent_motion), " %")) %>%
  group_by(Algorithm) %>%
  summarise(across(ABCD:HASC55,sum)) %>%
  gt() %>%
  tab_header("Total Scans") %>%
  opt_table_font("Times New Roman")
```


```{r}
motion_df %>%
  filter(bval > 0) %>%
  select(Algorithm = method, Model = setting, Denoising = denoising, percent_motion, scheme) %>%
  group_by(scheme) %>%
  summarise(`Total b > 0 Volumes` = n()) %>%
  t() %>%
  row_to_names(1) %>%
  data.frame() %>%
  gt(rownames_to_stub = TRUE) %>%
  opt_table_font("Times New Roman")
```

Note that errors for rotation are converted from radians to degrees, and
we also extract only the $b > 0$ volumes. Both Eddy and SHORELine use different
methods (non-GP and non-SHORE) for motion-correcting these images.

# Motion Analysis

## 1. Is there an RMSE difference between the Rigid/Affine and Linear/Quadratic settings?

We tested Rigid and Affine transformation models for SHORELine and Linear and 
Quadratic models in Eddy. In Eddy, the models only affect Eddy current correction
so we shouldn't see a difference in head motion estimates. SHORELine may or may 
not benefit from having more degrees of freedom in the transformation model. 

Here we test whether there are significant effects of transformation model.
Under the hood R will pair the same scans and perform a paired t-test by 
subtracting alphabetically. For SHORELine this means Affine - Rigid and 
for Eddy it means Linear - Quadratic. 

```{r check_setting}
# TODO put these long functions into a function

# TODO times new roman in the header and stub

setting_tests <- error_rmse_wsetting %>%
  rename(hmc_method=method) %>%
  group_by(denoising, scheme, motion.type, hmc_method, percent_motion) %>%
  do(test = tidy(t.test(rmse ~ setting, data=., paired=TRUE))) %>%
  unnest(test)

# Adjust the p-values and order them by the largest absolute effects
setting_tests_adj <- setting_tests %>% 
  select(!c(parameter, method, alternative)) %>%
  
  pivot_wider(
    names_from = motion.type, 
    values_from = c(estimate:conf.high)
    ) %>%
  
  # p adjust any pvalues
  mutate(
    across(
      contains("p.value"),
       ~p.adjust(.x),
      .names = "Adjusted_{.col}"
      )
    ) %>%

  # filter sig pvals
  # no eddy rows should get through this filter
  filter(if_any(contains("Adjusted"), ~.x < 0.01))

setting_tests_adj %>%
  select(Method = hmc_method, Scheme = scheme, Denoising = denoising, percent_motion, everything()) %>%      
  # reorder columns
  arrange(Method, Scheme, Denoising) %>%
  
  # convert to char for empty strings &
  # insert empty strings for every group where the values are duplicated
  # for clarity
  
  mutate(across(where(is.factor), as.character)) %>%  
  group_by(Method, Scheme, Denoising) %>%
  mutate_at(vars(Method:Denoising), ~ replace(.x, duplicated(.x), "")) %>%
  ungroup() %>%
  
  # precision for the confidence intervals that get merged
  mutate(across(contains("conf"), ~ round(.x, 2))) %>%
  select(!matches("^p.value")) %>%
  
  # last details
  mutate(Denoising = ifelse(Denoising == "none", "None", "DWIDenoise")) %>%
  
  
  gt(rowname_col = "Scheme") -> setting_tests_gt
  
setting_tests_gt %>%
  tab_spanner(label = md("*Rotation*"), columns = matches("Rotation")) %>%
  tab_spanner(label = md("*Translation*"), columns = matches("Translation")) %>%
  
  # string format confidence intervals
  cols_merge(columns = c(conf.low_Translation, conf.high_Translation), pattern = "[{1}, {2}]") %>%
  cols_label(
    conf.low_Translation = "95% CI"
  ) %>%
  cols_merge(columns = c(conf.low_Rotation, conf.high_Rotation), pattern = "[{1}, {2}]") %>%
  cols_label(
    conf.low_Rotation = "95% CI"
  ) %>%
  fmt(
    columns = matches("p.value"),
    fns = function(x){
      format.pval(x, eps=0.0001, digits = 3)
    }
  ) %>%
  fmt_number(
    columns = matches("statistic|estimate"),
    decimals = 3
  ) %>%
  cols_label(
    Adjusted_p.value_Rotation = md("Adj. *p*-value"),
    Adjusted_p.value_Translation = md("Adj. *p*-value"),
    estimate_Rotation = md("Estimate"),
    estimate_Translation = md("Estimate"),
    statistic_Rotation = md("Statistic"),
    statistic_Translation = md("Statistic"),
    percent_motion = md("% Motion")
  ) %>%
  
  data_color(
    columns = c(estimate_Translation, estimate_Rotation),
    colors = scales::col_numeric(
      palette = rocket(10),
      domain = c(-0.1, 0.5)
    )
  ) %>%
  tab_style(
    style = list(
      cell_text(font = "Times New Roman")
      ),
    locations = cells_body(
      columns = everything(),
      rows = everything()
    )
  ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
      ),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
      ),
    locations = cells_column_spanners(spanners = everything())
  ) %>%
  tab_header(md("**Predicting RMSE of Motion Estimates**"),
             subtitle = "Evaluation of Effects on Transformation") %>%
  opt_table_font("Times New Roman")
```


We can see that all the effects that survive a filter for $\text{Adjusted-}p < 0.01$ are for SHORELine and the estimates are
positive. This means that Affine RMSE is greater than Rigid RMSE. Although these 
estimates are all tiny, we will simplify subsequent comparisons by only choosing
rigid. Rigid also has the benefit of much shorter run times than Affine. As 
expected, there are no differences for Eddy.

We'll subset the RMSE values to just those we're using for the 
rest of the comparisons:

```{r compare_rmse}

# Only look at one setting per method
error_rmse <- error_rmse_wsetting %>% 
  filter(setting %in% c("Rigid", "Quadratic")) %>%
  select(-setting)
```

## 2. Summarization of Motion Detection Errors

Here we summarize how big errors were in estimating head motion. We first look
at the distribution of errors to check that it's centered around zero, and that this is 
the case for both eddy and shoreline.

```{r}
# TODO generally improve this plot

error_df_wsetting %>%
  select(method, scheme, denoising, percent_motion, motion.type, Error = value) %>%
  filter(Error < 20 & Error > -20) %>% # very egregious errors
  mutate(percent_motion = ordered(percent_motion, levels=c(50, 30, 15))) %>%
  ggplot(aes(x=Error, y=percent_motion, fill=scheme)) +
  stat_slab(alpha = 0.5, width = 0, .width = 0, point_colour = NA, expand=TRUE, color = "black") +
  facet_grid(method ~ motion.type, scales = "free") +
  ggtitle("Distribution of Motion Estimate Errors")
```

Next we see what the standard deviation
of the error is. This tells us, on average, the amount of degrees or mm we 
can expect an error to be for each method.

```{r plot_rmse_data_means, cache=TRUE}
# TODO put formatting into a function

rmse_summaries <- error_rmse %>%
  group_by(denoising, scheme, motion.type, method, percent_motion) %>%
  summarise(mean_rmse=mean(rmse), 
            sd_rmse=sd(rmse), 
            se_rmse=sd_rmse/sqrt(length(rmse)),
            group_mean_error=mean(mean_error),
            sd_mean_error=sd(mean_error))

rmse_summaries <- rmse_summaries %>%
  mutate(
    motion.type = case_when(
      str_detect(motion.type, "Rotation")  ~ "Rotation (degrees)",
      str_detect(motion.type, "Translation")  ~ "Translation (mm)"
      ),
    Denoising=case_when(denoising == "none"  ~ "None", TRUE ~ "MP-PCA") %>% factor()
    
  )

pd=position_dodge2(width=0.7, preserve="single")
linetypes = c("None" = 1, "MP-PCA" = 2)

error_mean_plt <-  ggplot(
    rmse_summaries,
    aes(
      y=group_mean_error, x=percent_motion, 
      color=method, fill=method)
    ) +
  geom_bar(aes(linetype=Denoising), stat="identity", position=pd, width = 0.6) +
  geom_errorbar(
    aes(ymax=group_mean_error+mean_rmse,
        ymin=group_mean_error-mean_rmse,
        linetype=Denoising,
        width=0.7),
    color = "black", position=pd
    ) +
  facet_grid(motion.type~scheme, scales="free") + 
  scale_color_manual(
    values=c("SHORELine"="#d95f02", "Eddy"="#1b9e77"), guide="none"
    ) +
  scale_fill_manual(
    values=c("SHORELine"="#d95f02", "Eddy"="#1b9e77")
    ) +
  scale_linetype_manual(
    name="Denoising Strategy",
    values=linetypes
    ) +
  theme_bw(
    base_family="Times",
    base_size=16
  ) +
  labs(title = "Head Motion Estimate Error", 
       y = "Mean Error (±Mean RMSE)", 
       x = "Percent Motion Volumes", 
       fill = "Method"
       ) +
  guides(linetype=guide_legend(override.aes=list(fill=NA)))
```

```{r, error_mean_plot, cache=TRUE}
# TODO reduce plot size, increase font size
error_mean_plt
```

```{r}
# Summarize the motion rmse in the different cells
rmse_plt <-  ggplot(
    rmse_summaries,
    aes(
      y=mean_rmse, x=percent_motion, 
      color=method, fill=method)
    ) +
  geom_bar(aes(linetype=Denoising), stat="identity", position=pd, width = 0.6) +
  geom_errorbar(
    aes(ymax=mean_rmse+sd_rmse, ymin=mean_rmse-sd_rmse,
        linetype=Denoising,
        width=0.7),
    color = "black", position=pd
    ) +
  facet_grid(motion.type~scheme, scales="free") + 
  scale_color_manual(
    values=c("SHORELine"="#d95f02", "Eddy"="#1b9e77"), guide="none"
    ) +
  scale_fill_manual(
    values=c("SHORELine"="#d95f02", "Eddy"="#1b9e77")
    ) +
  scale_linetype_manual(
    name="Denoising Strategy",
    values=linetypes
    ) +
  theme_bw(
    base_family="Times",
    base_size=16
  ) +
  labs(title = "Motion Estimate RMSE",
       y = "Mean RMSE (±SD)", 
       x = "Percent Motion Volumes", 
       fill = "Method",
       ) +
  guides(linetype=guide_legend(override.aes=list(fill=NA)))

```

```{r, rmse_plot, cache=TRUE}
rmse_plt
```

```{r, save plots, cache=TRUE, include=FALSE}
ggsave(here("vignettes","error_mean_plot.svg"),
       plot=error_mean_plt,
       height=4,
       width=7.9,
       units="in")

ggsave(here("vignettes","rmse_plot.svg"),
       plot=rmse_plt,
       height=4,
       width=7.9,
       units="in")
```

Here is how means were reported in the paper, and also how they were 
calculated for the OHBM poster.

```{r get_means}
# TODO formatting
errs <- error_rmse %>% group_by(motion.type) %>% 
  summarise(mean_mean_error=mean(mean_error),
            sd_mean_error=sd(mean_error))

errs %>%
  gt() %>%
  tab_header("Mean RMSE by Motion Type") %>%
  opt_table_font("Times New Roman")
```

## 3. Compare Performance on Sampling Schemes

There are 4 sampling schemes compared here. How well do the motion correction
methods work on each?


```{r compare_sampling_schemes}

rmse_summaries_collapsed <- error_rmse %>%
  group_by(scheme, motion.type, method, denoising) %>%
  summarise(mean_rmse=mean(rmse), 
            sd_rmse=sd(rmse), 
            se_rmse=sd_rmse/sqrt(length(rmse)),
            group_mean_error=mean(mean_error),
            sd_mean_error=sd(mean_error)) %>%
  mutate(denoised = recode(denoising, none="", dwidenoise="+ MP-PCA"),
         method_name = paste(method, denoised)) %>%
  select(-denoised) %>%
  filter(method_name != "SHORELine + MP-PCA") # no difference, so skip it

rmse_summaries_collapsed %>%
  ungroup() %>%
  mutate(
    num_directions = case_when(
      scheme == "ABCD"    ~ 103,
      scheme == "HCP"     ~ 270,
      scheme == "DSIQ5"   ~ 257,
      scheme == "HASC55"  ~ 55
    )
  ) %>%
# rmse_summaries_collapsed$num_directions <- recode(
#   rmse_summaries_collapsed$scheme,
#   ABCD=103,
#   HCP=270,
#   DSIQ5=257,
#   HASC55=55)

  mutate(
    denoiser = case_when(
      denoising == "none" ~ "None",
      TRUE                ~ "MP-PCA"
    )
  ) %>%
# rmse_summaries_collapsed$denoiser <- recode(
#   rmse_summaries_collapsed$denoising,
#   none="None",
#   dwidenoise="MP-PCA"
# )

  mutate(
    scheme_type = case_when(
      str_detect(scheme, "ABCD|HCP")  ~ "Shelled",
      TRUE                            ~ "Non-Shelled"
    )
  ) %>%
  
# rmse_summaries_collapsed$scheme_type = recode(
#   rmse_summaries_collapsed$scheme,
#   ABCD="Shelled",
#   HCP="Shelled",
#   DSIQ5="Non-Shelled",
#   HASC55="Non-Shelled")

  mutate(
    motion.type = case_when(
      str_detect(motion.type, "Rotation")     ~ "Rotation (degrees)",
      str_detect(motion.type, "Translation")  ~ "Tranlation (mm)",
    )
  ) -> rmse_summaries_collapsed
# rmse_summaries_collapsed$motion.type <- recode(
#   rmse_summaries_collapsed$motion.type,
#   Rotation="Rotation (degrees)",
#   Translation="Translation (mm)"
#   )

# Summarize the motion rmse in the different cells
pd2 = position_dodge(8)
directions_plt <-  ggplot(
    rmse_summaries_collapsed,
    aes(x=num_directions, y=mean_rmse,
        color=method,
        shape=scheme_type,
        linetype=denoiser,
        group=method_name)) +
  geom_errorbar(
    aes(ymax=mean_rmse+sd_rmse, ymin=mean_rmse-sd_rmse), 
    position=pd2) +
  geom_point(size=2, position=pd2) +
  geom_line() +
  facet_grid(motion.type~.) +
  theme_bw(
    base_family="Helvetica",
    base_size=12
  ) +
  scale_color_manual(
    labels=c("SHORELine", "Eddy"),
    values=c("SHORELine"="#d95f02", "Eddy"="#1b9e77")) +
  scale_linetype_manual(values=c("None"=1,"MP-PCA" = 2)) +
  labs(title = "RMSE by Scheme Type", 
       y = "Mean RMSE (±SD)", 
       x = "Number of Directions", 
       color = "Method",
       linetype= "Denoising\nMethod",
       shape="Scheme\nType")
```


```{r, cache=TRUE, include=FALSE}
ggsave(here("vignettes","directions_plot.svg"),
       plot=directions_plt,
       height=4,
       width=7.9,
       units="in")
```

```{r, cache=TRUE}
directions_plt
```

This is just another view of the previous plot, but interesting in that 
it clearly shows that SHORELine's performance on the 55-direction CS-DSI
scan is in the range of the performance on the ABCD multi shell scheme, which
has almost twice as many directions.
We can statistically test this, to be sure:

```{r test_ndirs}
error_rmse_dirs <- error_rmse

error_rmse_dirs$num_directions <- recode(
  error_rmse_dirs$scheme,
  ABCD=103,
  HCP=270,
  DSIQ5=257,
  HASC55=55)

error_rmse_dirs$scheme_type = recode(
  error_rmse_dirs$scheme,
  ABCD="Shelled",
  HCP="Shelled",
  DSIQ5="Non-Shelled",
  HASC55="Non-Shelled")

# Convert to percentage values
error_rmse_dirs$percent_motion <- with(
  error_rmse_dirs,
  as.numeric(levels(percent_motion))[percent_motion])

# run lm
rotation_shell_model <- lm(
  rmse ~ scheme_type * num_directions + denoising + percent_motion,
  data=subset(error_rmse_dirs, motion.type=="Rotation"))

translation_shell_model <- lm(
  rmse ~ scheme_type * num_directions + denoising + percent_motion,
  data=subset(error_rmse_dirs, motion.type=="Translation"))

```

```{r}
# create gt tables
translation_rmse_tab <- tbl_regression(
  translation_shell_model, 
  intercept=TRUE,
  estimate_fun = ~style_number(.x, digits=3)
  ) %>%
  bold_p() %>%
  bold_labels() %>% 
  italicize_levels()

rotation_rmse_tab <- tbl_regression(
  rotation_shell_model, 
  intercept=TRUE,
  estimate_fun = ~style_number(.x, digits=3)
  ) %>%
  bold_p() %>%
  bold_labels() %>% 
  italicize_levels()
  
```


```{r}
# merge and display

tbl_merge(list(translation_rmse_tab, rotation_rmse_tab), tab_spanner = c("Translation", "Rotation")) %>%
  as_gt() %>%
  fmt_number(n_sigfig = 2, matches("Beta"), force_sign = TRUE) %>%
  tab_header(title = "Models Predicting RMSE of Predicted Motion",
             subtitle = "Main Effects of Denoising, Number of Directions, and Percent Motion, including interactions with Shell Scheme") %>%
  tab_source_note(md("*This data is simulated*")) %>%
  opt_table_font("Times New Roman")
```

A couple interesting results come out here along with some obvious ones. First,
there is a main effect of the number of directions. The more directions, the
smaller the RMSE. 

## 4 Head to head comparison of SHORELine vs Eddy

The ABCD and HCP sequences are the only two schemes we tested that can be 
processed by both Eddy and SHORELine. 

```{r compare_shoreline_eddy}

# Match the Eddy and SHORELine errors 
paired_error <- error_rmse %>%
  select(-mean_error, -sd_error) %>%
  filter(scheme %in% c("ABCD", "HCP")) %>%
  spread(method, rmse, sep="_") %>% 
  group_by(scheme, motion.type) %>% 
  mutate(shore_difference=method_Eddy - method_SHORELine,
         percent_motion=as.numeric(levels(percent_motion))[percent_motion])

rotation_rmse_model_paired <- lm(
  shore_difference ~ scheme * denoising * percent_motion,
  data=subset(paired_error, motion.type=="Rotation"))

translation_rmse_model_paired <- lm(
  shore_difference ~ scheme * denoising * percent_motion,
  data=subset(paired_error, motion.type=="Translation"))
```

```{r}
translation_rmse_paired_tab <- tbl_regression(
  translation_rmse_model_paired, 
  intercept=TRUE,
  estimate_fun = ~style_number(.x, digits=3)
  ) %>%
  bold_p() %>%
  bold_labels() %>% 
  italicize_levels()

rotation_rmse_paired_tab <- tbl_regression(
  rotation_rmse_model_paired, 
  intercept=TRUE,
  estimate_fun = ~style_number(.x, digits=3)
  ) %>%
  bold_p() %>%
  bold_labels() %>% 
  italicize_levels()
```


```{r}
tbl_merge(list(translation_rmse_paired_tab, rotation_rmse_paired_tab), tab_spanner = c("Translation", "Rotation")) %>%
  as_gt() %>%
  fmt_number(n_sigfig = 2, matches("Beta"), force_sign = TRUE) %>%
  tab_header(title = "Predicting RMSE Difference (Eddy — SHORELine) in ABCD & HCP Schemes",
             subtitle = "Main Effects of Denoising & Percent Motion, and interactions with Shell Scheme") %>%
  tab_source_note(md("*This data is simulated*")) %>%
  tab_footnote(escape_latex(md("The SHORELine RMSE value was subtracted from the Eddy RMSE from each simulated scan, and this difference was the outcome variable of the model. Positive Beta estimates suggest better performance by SHORELine.")),
               locations = cells_title("title")) %>%
  opt_table_font("Times New Roman")
```

We plot the RMSE differences:

```{r rmse_diffs_boxplot, include=FALSE}
#TODO should we use this plot or the one below?
paired_error$percent_motion <- factor(paired_error$percent_motion)

ggplot(paired_error, 
       aes(x=as.factor(percent_motion), 
           y=shore_difference,
           fill=denoising)) +
  geom_hline(yintercept = 0) +
  geom_violin(draw_quantiles = 0.5) + 
  facet_grid(motion.type~scheme) +
  scale_fill_manual(
    labels=c("MP-PCA", "None"),
    values=c("dwidenoise"="#FFC20A", "none"="#0C7BDC")) +
  theme_bw(
    base_family="Helvetica",
    base_size=12) + 
  labs(
    title = "Difference in Estimation Error (Eddy - SHORELine)",
    y = "Estimation Error Difference",
    x = "Percent Motion Volumes",
    fill="Denoising\nMethod")

```

```{r}
ggplot(paired_error, 
       aes(x=as.factor(percent_motion), 
           y=shore_difference,
           fill=denoising)) +
  stat_halfeye(
    justification = -.2,
    alpha = 0.8,
    .width = 0, 
    point_colour = NA) +
  geom_boxplot(
    width = .12, 
    outlier.shape = NA ## `outlier.shape = NA` works as well
  ) +
  # geom_point(
  #   ## draw horizontal lines instead of points
  #   shape = 95,
  #   size = 10,
  #   alpha = 0.2,
  # ) +
  coord_cartesian(xlim = c(1.2, NA)) +
  facet_grid(motion.type~scheme, scales="free") +
  scale_fill_manual(
    labels=c("MP-PCA", "None"),
    values=c("dwidenoise"="#FFC20A", "none"="#0C7BDC")) +
  theme_bw(
    base_family="Helvetica",
    base_size=12) +
  labs(
    title = "Differences in Estimate Error (Eddy - SHORELine)",
    y = "Estimation Error Difference",
    x = "Percent Motion Volumes",
    fill="Denoising\nMethod")
```


# QC metric comparisons between SHORELine and Eddy

While accurately estimating head motion parameters is important, head motion
is not the only artifact present in the simulated data. Other factors like
eddy current distortion can impact the final quality of the results. 

We therefore calculated and compared the Neighboring DWI Correlation (NDC) 
and FWHM of the final outputs between the two methods. The NDC and FWHM of 
the results are related, so we used the same method as in Cieslak et al. 2021
where FWHM is partialled out from the NDC measurements.

## 1. Test the Settings

```{r}
data("qc_df")
```


Above we tested the settings to see if Linear/Quadratic or Rigid/Affine 
made a difference on motion estimation accuracy. Linear/Quadratic showed no
difference, but Rigid performed better than Affine. 

```{r check_settings_qc}
setting_tests <- qc_df %>%
  rename(hmc_method=method) %>%
  group_by(denoising, scheme, hmc_method, percent_motion) %>%
  do(test = tidy(t.test(ndc.corrected ~ setting, data=., paired=TRUE))) %>%
  unnest(test)

# Adjust the p-values and order them by the largest absolute effects
setting_tests <- setting_tests %>%
  mutate(p.value.adj = p.adjust(p.value))
# 
# significant.effects <- subset(setting_tests, (p.value.adj < 0.01))
# significant.effects[order(-abs(significant.effects$estimate)),]

setting_tests_gt <- setting_tests %>% 
  select(!c(parameter, method, alternative)) %>%
  select(Method = hmc_method, Scheme = scheme, Denoising = denoising, percent_motion, everything()) %>%
  arrange(Method, Scheme, Denoising) %>%
  
  # convert to char for empty strings &
  # insert empty strings for every group where the values are duplicated
  # for clarity
  
  mutate(across(where(is.factor), as.character)) %>%  
  group_by(Method, Scheme, Denoising) %>%
  mutate_at(vars(Method:Denoising), ~ replace(.x, duplicated(.x), "")) %>%
  ungroup() %>%
  
  # precision for the confidence intervals that get merged
  mutate(across(contains("conf"), ~ round(.x, 2))) %>%
  
  # last details
  mutate(Denoising = ifelse(Denoising == "none", "None", "DWIDenoise")) %>%
  select(-p.value) %>%
  mutate(pval_marker = p.value.adj) %>%
  mutate(percent_motion = paste0(as.character(percent_motion), " %")) %>%
  
  gt(rowname_col = "Scheme")
```

```{r}
setting_tests_gt %>%
  cols_merge(columns = c(conf.low, conf.high), pattern = "[{1}, {2}]") %>%
  cols_label(
    conf.low = "95% CI"
  ) %>%
  fmt(
    columns = matches("p.value.adj"),
    fns = function(x){
      format.pval(x, eps=0.0001, digits = 3)
    }
  ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
      ),
    locations = cells_body(columns = p.value.adj, rows = pval_marker < 0.01)
  ) %>%
  fmt_number(
    columns = matches("statistic|estimate"),
    decimals = 3
  ) %>%
  cols_label(
    p.value.adj = md("Adj. *p*-value"),
    estimate = md("Estimate"),
    statistic = md("Statistic"),
    percent_motion = md("% Motion")
  ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
      ),
    locations = cells_column_labels(columns = everything())
  ) %>%
  opt_table_font("Times New Roman")
```

Recall here we're testing NDC, which is better when higher. The t-tests work 
the same way here as they did above: all the significant effects are for SHORELine and the 
estimates are positive. This means that Affine NDC is higher than Rigid NDC. 
Although these effects are absolutely tiny, they have a different direction
than the RMSE tests: Affine produces higher QC metrics than Rigid, while Rigid
is more accurate at estimating head motion than Affine. 

To be consistent with the above tests, we will use Rigid for the QC comparisons.
Rigid is also remarkably faster than Affine, and could be the first step
of a more powerful Eddy Current correction later.

```{r qc_select_setting}
qc_df <- qc_df %>% 
  filter(setting %in% c("Rigid", "Quadratic")) %>%
  select(-setting)

```

## 2. How does the fwhm compare?

```{r fwhm_plot}
fwhm_smooth_plot <- qc_df %>%
  ggplot(aes(x=factor(percent_motion), y=fwhm, fill=method)) +
  stat_halfeye(
    justification = -.2,
    alpha = 0.8,
    .width = 0, 
    point_colour = NA) +
  geom_boxplot(
    position = position_dodge2(width = 5, preserve = "single", padding= 0.02),
    width = .12,
    alpha = 0.8,
    outlier.shape = NA ## `outlier.shape = NA` works as well
  ) +

  scale_fill_manual(
    values=c("SHORELine"="#d95f02", "Eddy"="#1b9e77")) +
  theme_bw(
    base_family="Times",
    base_size=12
  ) +
  labs(title = "Spatial Smoothness (FWHM)", 
       y = "FWHM (mm)", 
       x = "Percent Motion Volumes", 
       fill = "Method") +
  facet_wrap(~scheme, ncol=2)
```

```{r}
fwhm_smooth_plot
```

```{r}
ggsave(here("vignettes","fwhm_smooth_plot.svg"),
       plot=fwhm_smooth_plot,
       height=3,
       width=7.9,
       units="in")
```


```{r fwhm_stats}
# What about if we make a paired comparison?
id_cols <- c("scheme", "iternum", "method", "denoising", "percent_motion")

paired_fwhm <- qc_df %>% 
  select(one_of(c(id_cols, "fwhm"))) %>%
  spread(method, fwhm, sep="_") %>%
  mutate(fwhm_diff=method_SHORELine - method_Eddy,
         percent_motion = as.factor(percent_motion)) %>%
  select(-starts_with("method_"))
fwhm_diff_model <- lm(
  fwhm_diff ~ percent_motion + scheme + denoising,
  data=paired_fwhm)
```

```{r}
tbl_regression(
  fwhm_diff_model,
  intercept=TRUE,
  estimate_fun = ~style_number(.x, digits=3)
  ) %>%
  bold_p() %>%
  bold_labels() %>% 
  italicize_levels() %>%
  as_gt() %>%
  tab_header(title = "Linear Model Predicting FWHM (Eddy — Shoreline) of Each Scan",
             subtitle = "Main Effects of Percent Motion, Scheme, and Denoising") %>%
  tab_source_note(md("*This data is simulated*")) %>%
  
  
```


## 3. Comparing FWHM-corrected NDC between SHORELine and Eddy

Does one of the methods have higher NDC scores? Also what is the improvement in
NDC relative to the raw data? We know that higher percent motion will cause 
lower NDC scores in the unprocessed data.

```{r qc_stats}

improved_ndc_summaries <- qc_df %>%
  group_by(denoising, scheme, method, percent_motion) %>%
  summarise(mean_ndc=mean(improved.ndc.corrected), 
            sd_ndc=sd(improved.ndc.corrected), 
            se_ndc=sd_ndc/sqrt(length(improved.ndc.corrected)),
            group_mean_ndc=mean(mean_ndc),
            sd_mean_ndc=sd(mean_ndc))
improved_ndc_summaries$measure <- 'NDC Change From Raw'
ndc_summaries <- qc_df %>%
  group_by(denoising, scheme, method, percent_motion) %>%
  summarise(mean_ndc=mean(ndc.corrected), 
            sd_ndc=sd(ndc.corrected), 
            se_ndc=sd_ndc/sqrt(length(ndc.corrected)),
            group_mean_ndc=mean(mean_ndc),
            sd_mean_ndc=sd(mean_ndc))
ndc_summaries$measure <- 'Mean Preprocessed NDC'
qc_summaries <- rbind(ndc_summaries, improved_ndc_summaries)
qc_summaries$percent_motion <- as.factor(qc_summaries$percent_motion)

```

```{r}
pd=position_dodge(width=0.7, preserve="single")

ndc_mean_plt <-  ggplot(
    qc_summaries,
    aes(x=percent_motion, 
        y=group_mean_ndc, 
        fill=method, 
        pattern_alpha=denoising)) +
  scale_pattern_type_discrete(
    choices=c("hatch")) +
  geom_col_pattern(position=pd,
                   width=0.5,
                   pattern_spacing=0.03,
                   pattern_fill="black",
                   color="black") +
  scale_pattern_alpha_discrete(
    range=c(0,.7),
    labels=c("MP-PCA", "None")) +
  geom_errorbar(
    aes(ymax=group_mean_ndc+sd_ndc, ymin=group_mean_ndc-sd_ndc, width=0.7), 
    position=pd) +
  facet_grid(measure~scheme, scales = "free_y") + 
  scale_fill_manual(
    values=c("SHORELine"="#d95f02", "Eddy"="#1b9e77")) +
  theme_bw(
    base_family="Helvetica",
    base_size=12
  ) +
  labs(title = "QC Measure", 
       y = "Neighboring DWI Correlation", 
       x = "Percent Motion Volumes",
       fill = "Method",
       pattern_alpha="Denoising\nMethod")
```

```{r}
ndc_mean_plt
```


```{r}
ggsave(here("vignettes","ndc_mean_plot.svg"),
       plot=ndc_mean_plt,
       height=3,
       width=7.9,
       units="in")
```

The NDC scores in and of themselves don't mean much across sampling schemes,
but are comparable within sampling schemes. The top row shows that MP-PCA 
improves NDC scores across the board and also that Eddy has a small advantage 
in the two shelled schemes where it can be used.

The second row shows the percent improvement in NDC relative to the raw scans.
This is pretty remarkable. To do statistical tests, we will center the raw
NDC *within* their percent motion category

```{r}
qc_df <- subset(qc_df, scheme %in% c("ABCD", "HCP"))

ggplot(qc_df, aes(x=percent_motion, y=raw_neighbor_corr, color=scheme)) + 
  geom_jitter() +
  ggtitle("Unprocessed data NDC values")
```


```{r center_raw_ndc}
qc_df <- qc_df %>%
   group_by(percent_motion) %>%
   mutate(pct_motion_mean=median(raw_neighbor_corr),
          centered_raw_ndc=raw_neighbor_corr - pct_motion_mean)

ggplot(qc_df, aes(x=percent_motion, y=centered_raw_ndc, color=scheme)) + 
  geom_jitter() +
  ggtitle("Unprocessed data NDC values: Centered by percent motion")
```


```{r ndc_stats}
paired_ndc <- qc_df %>% 
  select(one_of(c(id_cols, "ndc.corrected"))) %>%
  spread(method, ndc.corrected, sep="_") %>%
  mutate(ndc_diff=method_SHORELine - method_Eddy) %>%
  select(-starts_with("method_"))

ndc_diff_model <- lm(
  ndc_diff ~ percent_motion + denoising + scheme,
  data=paired_ndc)
```

```{r}
tbl_regression(
  ndc_diff_model,
  intercept=TRUE,
  estimate_fun = ~style_number(.x, digits=3)
  ) %>%
  bold_p() %>%
  bold_labels() %>% 
  italicize_levels() %>%
  as_gt() %>%
  tab_header(title = "NDC Model") %>%
  tab_source_note(md("*This data is simulated*"))
```

