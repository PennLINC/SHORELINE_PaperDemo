---
title: "Head Motion Benchmark"
author: "Matt Cieslak PhD"
date: "4/16/2022"
output: html_document
---

# Libraries & Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(broom)
library(ggpattern)
library(emmeans)
library(gtsummary)
library(gt)
```

The data are available on OSF at [this link](osf.io/7twne).
This package internally downloads and cleans them for
your convenience. They're available like so:

```{r}
data("motion_df") # for viewing the preprocessed data
data("error_rmse_wsetting") # for analysis of estimated motion
```

# Sample

The table below shows the number of `b0`'s for each scheme:

```{r}
# TODO demonstrate the table in the paper

motion_df %>%
  filter(
    iternum == 1 &
      method == "SHORELine" &
      denoising == "none" &
      bval > 100 &
      setting == "Affine") %>%
   select(percent_motion, scheme) %>%
   table()
```



Errors for rotation are converted from radians to degrees, and
we also extract only the $b > 0$ volumes. Both Eddy and SHORELine use different
methods (non-GP and non-SHORE) for motion-correcting these images.

# Analysis

## 1. Is there an RMSE difference between the Rigid/Affine and Linear/Quadratic settings?

We tested Rigid and Affine transformation models for SHORELine and Linear and 
Quadratic models in Eddy. In Eddy, the models only affect Eddy current correction
we shouldn't see a difference in head motion estimates. SHORELine may or may 
not benefit from having more degrees of freedom in the transformation model. 

Here we test whether there are significant effects of transformation model.
Under the hood R will pair the same scans and perform a paired t-test by 
subtracting alphabetically. For SHORELine this means Affine - Rigid and 
for Eddy it means Linear - Quadratic. 


```{r check_setting}
setting_tests <- error_rmse_wsetting %>%
  rename(hmc_method=method) %>%
  group_by(denoising, scheme, motion.type, hmc_method, percent_motion) %>%
  do(test = tidy(t.test(rmse ~ setting, data=., paired=TRUE))) %>%
  unnest(test)

# Adjust the p-values and order them by the largest absolute effects
setting_tests %>%
  mutate(p_val_adjusted = p.adjust(p.value)) %>%
  filter(p_val_adjusted < 0.01) %>%
  arrange(-abs(estimate))
```

We can see that all the effects are for SHORELine and the estimates are
positive. This means that Affine RMSE is greater than Rigid RMSE. Although these 
estimates are all tiny, we will simplify subsequent comparisons by only choosing
rigid. Rigid also has the benefit of much shorter run times than Affine. As 
expected, there are no differences for Eddy.

This section subsets the RMSE values to just those we're using for the 
rest of the comparisons:

```{r compare_rmse}

# Only look at one setting per method
error_rmse <- error_rmse_wsetting %>% 
  filter(setting %in% c("Rigid", "Quadratic")) %>%
  select(-setting)
```

## 2. Summarization of Motion Detection Errors

Here we summarize how big errors were in estimating head motion. We first look
at the distribution of errors to check that it's centered around zero. This is 
the case for both eddy and shoreline. 

Next we see what the standard deviation
of the error is. This tells us, on average, the amount of degrees or mm we 
can expect an error to be for each method.

```{r plot_rmse_data_means, cache=TRUE}
rmse_summaries <- error_rmse %>%
  group_by(denoising, scheme, motion.type, method, percent_motion) %>%
  summarise(mean_rmse=mean(rmse), 
            sd_rmse=sd(rmse), 
            se_rmse=sd_rmse/sqrt(length(rmse)),
            group_mean_error=mean(mean_error),
            sd_mean_error=sd(mean_error))

rmse_summaries <- rmse_summaries %>%
  mutate(motion.type = case_when(
    str_detect(motion.type, "Rotation")  ~ "Rotation (degrees)",
    str_detect(motion.type, "Translation")  ~ "Translation (mm)",
  ))

pd=position_dodge(width=0.7, preserve="single")

error_mean_plt <-  ggplot(
    rmse_summaries,
    aes(x=percent_motion, y=group_mean_error, 
        fill=method, pattern_alpha=denoising)) +
  scale_pattern_type_discrete(
    choices=c("hatch")) +
  geom_col_pattern(position=pd,
                   width=0.5,
                   pattern_spacing=0.03,
                   pattern_fill="black",
                   color="black") +
  scale_pattern_alpha_discrete(
    range=c(0,.7),
    labels=c("MP-PCA", "None")) +
  geom_errorbar(
    aes(ymax=group_mean_error+mean_rmse, 
        ymin=group_mean_error-mean_rmse, 
        width=0.7), 
    position=pd) +
  facet_grid(motion.type~scheme) + 
  scale_fill_manual(
    values=c("SHORELine"="#d95f02", "Eddy"="#1b9e77")) +
  theme_bw(
    base_family="Helvetica",
    base_size=12
  ) +
  labs(title = "Head Motion Estimate Error", 
       y = "Mean Error (±Mean RMSE)", 
       x = "Percent Motion Volumes", 
       fill = "Method",
       pattern_alpha="Denoising\nMethod") +
  coord_fixed()


# Summarize the motion rmse in the different cells
rmse_plt <-  ggplot(
    rmse_summaries,
    aes(x=percent_motion, 
        y=mean_rmse, 
        fill=method, 
        pattern_alpha=denoising)) +
  scale_pattern_type_discrete(
    choices=c("hatch")) +
  geom_col_pattern(position=pd,
                   width=0.5,
                   pattern_spacing=0.03,
                   pattern_fill="black",
                   color="black") +
  scale_pattern_alpha_discrete(
    range=c(0,.7),
    labels=c("MP-PCA", "None")) +
  geom_errorbar(
    aes(ymax=mean_rmse+sd_rmse, ymin=mean_rmse-sd_rmse, width=0.7), 
    position=pd) +
  facet_grid(motion.type~scheme) + 
  scale_fill_manual(
    values=c("SHORELine"="#d95f02", "Eddy"="#1b9e77")) +
  theme_bw(
    base_family="Helvetica",
    base_size=12
  ) +
  labs(title = "Motion Estimate RMSE",
       y = "Mean RMSE (±SD)", 
       x = "Percent Motion Volumes", 
       fill = "Method",
       pattern_alpha="Denoising\nMethod") +
  coord_fixed()

```

```{r, save plots, cache=TRUE}
ggsave(here("figures/error_mean_plot.svg"),
       plot=error_mean_plt,
       height=4,
       width=7.9,
       units="in")

ggsave(here("figures/rmse_plot.svg"),
       plot=rmse_plt,
       height=4,
       width=7.9,
       units="in")
```



```{r, cache=TRUE}
error_mean_plt
```

```{r, cache=TRUE}
rmse_plt
```

Here is how means were reported in the paper, and also how they were 
calculated for the OHBM poster.

```{r get_means}
errs <- error_rmse %>% group_by(motion.type) %>% 
  summarise(mean_mean_error=mean(mean_error),
            sd_mean_error=sd(mean_error))
tbl_summary(error_rmse, by = motion.type, statistic = list(all_continuous() ~ "{mean} ({sd})"), include = )

```

## 3. Compare Performance on Sampling Schemes

There are 4 sampling schemes compared here. How well do the motion correction
methods work on each?


```{r compare_sampling_schemes}

rmse_summaries_collapsed <- error_rmse %>%
  group_by(scheme, motion.type, method, denoising) %>%
  summarise(mean_rmse=mean(rmse), 
            sd_rmse=sd(rmse), 
            se_rmse=sd_rmse/sqrt(length(rmse)),
            group_mean_error=mean(mean_error),
            sd_mean_error=sd(mean_error)) %>%
  mutate(denoised = recode(denoising, none="", dwidenoise="+ MP-PCA"),
         method_name = paste(method, denoised)) %>%
  select(-denoised) %>%
  filter(method_name != "SHORELine + MP-PCA") # no difference, so skip it

rmse_summaries_collapsed$num_directions <- recode(
  rmse_summaries_collapsed$scheme,
  ABCD=103,
  HCP=270,
  DSIQ5=257,
  HASC55=55)

rmse_summaries_collapsed$denoiser <- recode(
  rmse_summaries_collapsed$denoising,
  none="None",
  dwidenoise="MP-PCA"
)

rmse_summaries_collapsed$scheme_type = recode(
  rmse_summaries_collapsed$scheme,
  ABCD="Shelled",
  HCP="Shelled",
  DSIQ5="Non-Shelled",
  HASC55="Non-Shelled")

rmse_summaries_collapsed$motion.type <- recode(
  rmse_summaries_collapsed$motion.type,
  Rotation="Rotation (degrees)",
  Translation="Translation (mm)"
  )

# Summarize the motion rmse in the different cells
pd2 = position_dodge(8)
directions_plt <-  ggplot(
    rmse_summaries_collapsed,
    aes(x=num_directions, y=mean_rmse,
        color=method,
        shape=scheme_type,
        linetype=denoiser,
        group=method_name)) +
  geom_errorbar(
    aes(ymax=mean_rmse+sd_rmse, ymin=mean_rmse-sd_rmse), 
    position=pd2) +
  geom_point(size=2, position=pd2) +
  geom_line() +
  facet_grid(motion.type~.) +
  theme_bw(
    base_family="Helvetica",
    base_size=12
  ) +
  scale_color_manual(
    labels=c("SHORELine", "Eddy"),
    values=c("SHORELine"="#d95f02", "Eddy"="#1b9e77")) +
  scale_linetype_manual(values=c("None"=1,"MP-PCA" = 2)) +
  labs(title = "RMSE by Scheme Type", 
       y = "Mean RMSE (±SD)", 
       x = "Number of Directions", 
       color = "Method",
       linetype= "Denoising\nMethod",
       shape="Scheme\nType")
```


```{r, cache=TRUE}
ggsave(here("figures", "directions_plot.svg"),
       plot=directions_plt,
       height=4,
       width=7.9,
       units="in")
```

```{r, cache=TRUE}
directions_plt
```

This is just another view of the previous plot, but interesting in that 
it clearly shows that SHORELine's performance on the 55-direction CS-DSI
scan is in the range of the performance on the ABCD multi shell scheme, which
has almost twice as many directions.
Better statistically test this to be sure:

```{r test_ndirs}
error_rmse_dirs <- error_rmse

error_rmse_dirs$num_directions <- recode(
  error_rmse_dirs$scheme,
  ABCD=103,
  HCP=270,
  DSIQ5=257,
  HASC55=55)

error_rmse_dirs$scheme_type = recode(
  error_rmse_dirs$scheme,
  ABCD="Shelled",
  HCP="Shelled",
  DSIQ5="Non-Shelled",
  HASC55="Non-Shelled")

# Convert to percentage values
error_rmse_dirs$percent_motion <- with(
  error_rmse_dirs,
  as.numeric(levels(percent_motion))[percent_motion])

rotation_shell_model <- lm(
  rmse ~ scheme_type * num_directions + denoising + percent_motion,
  data=subset(error_rmse_dirs, motion.type=="Rotation"))

translation_shell_model <- lm(
  rmse ~ scheme_type * num_directions + denoising + percent_motion,
  data=subset(error_rmse_dirs, motion.type=="Translation"))

```

```{r}
tbl_regression(
  translation_shell_model, 
  show_single_row=c("scheme_type", "denoising"), intercept=TRUE) %>%
  bold_p() %>%
  bold_labels() %>% 
  italicize_levels()
```

```{r}
tbl_regression(
  rotation_shell_model, 
  show_single_row=c("scheme_type", "denoising"), intercept=TRUE) %>%
  bold_p() %>%
  bold_labels() %>% 
  italicize_levels()
```

A couple interesting results come out here along with some obvious ones. First,
there is a main effect of the number of directions. The more directions, the
smaller the RMSE. 

## 4 Head to head comparison of SHORELine vs Eddy

The ABCD and HCP sequences are the only two schemes we tested that can be 
processed by both Eddy and SHORELine. 

```{r compare_shoreline_eddy}

# Match the Eddy and SHORELine errors 
paired_error <- error_rmse %>%
  select(-mean_error, -sd_error) %>%
  filter(scheme %in% c("ABCD", "HCP")) %>%
  spread(method, rmse, sep="_") %>% 
  group_by(scheme, motion.type) %>% 
  mutate(shore_difference=method_Eddy - method_SHORELine,
         percent_motion=as.numeric(levels(percent_motion))[percent_motion])

rotation_rmse_model_paired <- lm(
  shore_difference ~ scheme * denoising * percent_motion,
  data=subset(paired_error, motion.type=="Rotation"))
summary(rotation_rmse_model_paired)


translation_rmse_model_paired <- lm(
  shore_difference ~ scheme * denoising * percent_motion,
  data=subset(paired_error, motion.type=="Translation"))
```

```{r}
tbl_regression(
  translation_rmse_model_paired, intercept=TRUE) %>%
  bold_p() %>%
  bold_labels() %>% 
  italicize_levels()
```


Plot the RMSE differences
```{r rmse_diffs_boxplot}
paired_error$percent_motion <- factor(paired_error$percent_motion)

ggplot(paired_error, 
       aes(x=as.factor(percent_motion), 
           y=shore_difference,
           fill=denoising)) +
  geom_hline(yintercept = 0) +
  geom_violin(draw_quantiles = 0.5) + 
  facet_grid(motion.type~scheme) +
  scale_fill_manual(
    labels=c("MP-PCA", "None"),
    values=c("dwidenoise"="#FFC20A", "none"="#0C7BDC")) +
  theme_bw(
    base_family="Helvetica",
    base_size=12) + 
  labs(
    title = "Difference in Estimation Error (Eddy - SHORELine)",
    y = "Estimation Error Difference",
    x = "Percent Motion Volumes",
    fill="Denoising\nMethod")

```

# 5 QC metric comparisons between SHORELine and Eddy

While accurately estimating head motion parameters is important, head motion
is not the only artifact present in the simulated data. Other factors like
eddy current distortion can impact the final quality of the results. 

We therefore calculated and compared the Neighboring DWI Correlation (NDC) 
and FWHM of the final outputs between the two methods. The NDC and FWHM of 
the results are related, so we used the same method as in Cieslak et al. 2021
where FWHM is partialled out from the NDC measurements.

## Test the Settings

```{r}
data("qc_df")
```


Above we tested the settings to see if Linear/Quadratic or Rigid/Affine 
made a difference on motion estimation accuracy. Linear/Quadratic showed no
difference, but Rigid performed better than Affine. 

```{r check_settings_qc}
setting_tests <- qc_df %>%
  rename(hmc_method=method) %>%
  group_by(denoising, scheme, hmc_method, percent_motion) %>%
  do(test = tidy(t.test(ndc.corrected ~ setting, data=., paired=TRUE))) %>%
  unnest(test)

# Adjust the p-values and order them by the largest absolute effects
setting_tests$p.value.adj <- p.adjust(setting_tests$p.value)
significant.effects <- subset(setting_tests, (p.value.adj < 0.01))
significant.effects[order(-abs(significant.effects$estimate)),]

```

Recall here we're testing NDC, which is better when higher. The t-tests work 
the same way here as they did above: all the effects are for SHORELine and the 
estimates are positive. This means that Affine NDC is higher than Rigid NDC. 
Although these effects are absolutely tiny, they have a different direction
than the RMSE tests: Affine produces higher QC metrics than Rigid, while Rigid
is more accurate at estimating head motion than Affine. 

To be consistent with the above tests, we will use Rigid for the QC comparisons.
Rigid is also remarkably faster than Affine, and could be the first step
of a more powerful Eddy Current correction later.

```{r qc_select_setting}
qc_df <- subset(qc_df, setting %in% c("Rigid", "Quadratic"))
qc_df$setting <- NULL
```

## How does the fwhm compare?

```{r fwhm_plot}
ggplot(qc_df, aes(x=factor(percent_motion), y=fwhm, fill=method)) + 
  geom_hline(yintercept = 0) +
  geom_violin(draw_quantiles = 0.5) + 
  scale_fill_manual(
    values=c("SHORELine"="#d95f02", "Eddy"="#1b9e77")) +
  theme_bw(
    base_family="Helvetica",
    base_size=12
  ) +
  labs(title = "Spatial Smoothness (FWHM)", 
       y = "FWHM (mm)", 
       x = "Percent Motion Volumes", 
       fill = "Method") +
  facet_grid(.~scheme) + ylim(3.5,4.5)
```


```{r fwhm_stats}
# What about if we make a paired comparison?
id_cols <- c("scheme", "iternum", "method", "denoising", "percent_motion")
paired_fwhm <- qc_df %>% 
  select(one_of(c(id_cols, "fwhm"))) %>%
  spread(method, fwhm, sep="_") %>%
  mutate(fwhm_diff=method_SHORELine - method_Eddy,
         percent_motion = as.factor(percent_motion)) %>%
  select(-starts_with("method_"))
fwhm_diff_model <- lm(
  fwhm_diff ~ percent_motion + scheme + denoising,
  data=paired_fwhm)
summary(fwhm_diff_model)

```

## Comparing FWHM-corrected NDC between SHORELine and Eddy

Does one of the methods have higher NDC scores? Also what is the improvement in
NDC relative to the raw data? We know that higher percent motion will cause 
lower NDC scores in the unprocessed data.

```{r qc_stats}

improved_ndc_summaries <- qc_df %>%
  group_by(denoising, scheme, method, percent_motion) %>%
  summarise(mean_ndc=mean(improved.ndc.corrected), 
            sd_ndc=sd(improved.ndc.corrected), 
            se_ndc=sd_ndc/sqrt(length(improved.ndc.corrected)),
            group_mean_ndc=mean(mean_ndc),
            sd_mean_ndc=sd(mean_ndc))
improved_ndc_summaries$measure <- 'NDC Change From Raw'
ndc_summaries <- qc_df %>%
  group_by(denoising, scheme, method, percent_motion) %>%
  summarise(mean_ndc=mean(ndc.corrected), 
            sd_ndc=sd(ndc.corrected), 
            se_ndc=sd_ndc/sqrt(length(ndc.corrected)),
            group_mean_ndc=mean(mean_ndc),
            sd_mean_ndc=sd(mean_ndc))
ndc_summaries$measure <- 'Mean Preprocessed NDC'
qc_summaries <- rbind(ndc_summaries, improved_ndc_summaries)
qc_summaries$percent_motion <- as.factor(qc_summaries$percent_motion)

pd=position_dodge(width=0.7, preserve="single")

ndc_mean_plt <-  ggplot(
    qc_summaries,
    aes(x=percent_motion, 
        y=group_mean_ndc, 
        fill=method, 
        pattern_alpha=denoising)) +
  scale_pattern_type_discrete(
    choices=c("hatch")) +
  geom_col_pattern(position=pd,
                   width=0.5,
                   pattern_spacing=0.03,
                   pattern_fill="black",
                   color="black") +
  scale_pattern_alpha_discrete(
    range=c(0,.7),
    labels=c("MP-PCA", "None")) +
  geom_errorbar(
    aes(ymax=group_mean_ndc+sd_ndc, ymin=group_mean_ndc-sd_ndc, width=0.7), 
    position=pd) +
  facet_grid(measure~scheme, scales = "free_y") + 
  scale_fill_manual(
    values=c("SHORELine"="#d95f02", "Eddy"="#1b9e77")) +
  theme_bw(
    base_family="Helvetica",
    base_size=12
  ) +
  labs(title = "QC Measure", 
       y = "Neighboring DWI Correlation", 
       x = "Percent Motion Volumes",
       fill = "Method",
       pattern_alpha="Denoising\nMethod")
ndc_mean_plt

```

```{r}
ggsave(here("figures", "ndc_mean_plot.svg"),
       plot=ndc_mean_plt,
       height=3,
       width=7.9,
       units="in")
```

The NDC scores in and of themselves don't mean much across sampling schemes,
but are comparable within sampling schemes. The top row shows that MP-PCA 
improves NDC scores across the board and also that Eddy has a small advantage 
in the two shelled schemes where it can be used.

The second row shows the percent improvement in NDC relative to the raw scans.
This is pretty remarkable. To do statistical tests, we will center the raw
NDC *within* their percent motion category

```{r}
qc_df <- subset(qc_df, scheme %in% c("ABCD", "HCP"))

ggplot(qc_df, aes(x=percent_motion, y=raw_neighbor_corr, color=scheme)) + 
  geom_jitter() +
  ggtitle("Unprocessed data NDC values")
```


```{r center_raw_ndc}
qc_df <- qc_df %>%
   group_by(percent_motion) %>%
   mutate(pct_motion_mean=median(raw_neighbor_corr),
          centered_raw_ndc=raw_neighbor_corr - pct_motion_mean)

ggplot(qc_df, aes(x=percent_motion, y=centered_raw_ndc, color=scheme)) + 
  geom_jitter() +
  ggtitle("Unprocessed data NDC values: Centered by percent motion")
```


```{r ndc_stats}
paired_ndc <- qc_df %>% 
  select(one_of(c(id_cols, "ndc.corrected"))) %>%
  spread(method, ndc.corrected, sep="_") %>%
  mutate(ndc_diff=method_SHORELine - method_Eddy) %>%
  select(-starts_with("method_"))

ndc_diff_model <- lm(
  ndc_diff ~ percent_motion + denoising + scheme,
  data=paired_ndc)
summary(ndc_diff_model)
```
